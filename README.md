<h2> Vision Language Navigation Papers </h2>

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(1).pdf" style="text-decoration:none;">Self-Monitoring Navigation Agent via Auxiliary Progress Estimation</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(2).pdf" style="text-decoration:none;">Beyond the Nav-Graph: Vision-and-Language Navigation in Continuous Environments</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(3).pdf" style="text-decoration:none;">Speaker-Follower Models for
Vision-and-Language Navigation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(4).pdf" style="text-decoration:none;">Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(5).pdf" style="text-decoration:none;">Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(6).pdf" style="text-decoration:none;">The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(7).pdf" style="text-decoration:none;">Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-training</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(8).pdf" style="text-decoration:none;"> Counterfactual Vision-and-Language Navigation via Adversarial Path Sampler </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(9).pdf" style="text-decoration:none;">Improving Vision-and-Language Navigation with Image-Text Pairs from the Web</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(10).pdf" style="text-decoration:none;">Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language Navigation </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(11).pdf" style="text-decoration:none;">Active Visual Information Gathering for Vision-Language Navigation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(12).pdf" style="text-decoration:none;">Vision-Language Navigation with Self-Supervised Auxiliary Reasoning Tasks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(13).pdf" style="text-decoration:none;">TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(14).pdf" style="text-decoration:none;">Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(15).pdf" style="text-decoration:none;">Cross-Lingual Vision-Language Navigationt</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(16).pdf" style="text-decoration:none;">Look Before You Leap:
Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(17).pdf" style="text-decoration:none;">Shifting the Baseline:
Single Modality Performance on Visual Navigation and QA</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(18).pdf" style="text-decoration:none;">Unsupervised Reinforcement Learning of Transferable Meta-Skills for Embodied Navigation</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(19).pdf" style="text-decoration:none;">Vision-Dialog Navigation by Exploring Cross-modal Memory</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(20).pdf" style="text-decoration:none;">Robust Navigation with Language Pretraining and Stochastic Sampling</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(21).pdf" style="text-decoration:none;">REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(22).pdf" style="text-decoration:none;">Just Ask:
An Interactive Learning Framework for Vision and Language Navigation</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(23).pdf" style="text-decoration:none;">Vision-and-Dialog Navigation</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(24).pdf" style="text-decoration:none;">Talk the Walk: Navigating New York City through Grounded Dialogue</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(25).pdf" style="text-decoration:none;">Chasing Ghosts: Instruction Following as Bayesian State Tracking</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(26).pdf" style="text-decoration:none;">Embodied Vision-and-Language Navigation with Dynamic Convolutional Filters</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(27).pdf" style="text-decoration:none;">Learning to Follow Directions in Street View</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(28).pdf" style="text-decoration:none;">Environment-agnostic Multitask Learning for Natural Language Grounded Navigation</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(29).pdf" style="text-decoration:none;">HoME: a Household Multimodal Environment </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(30).pdf" style="text-decoration:none;">Multi-modal Discriminative Model for Vision-and-Language Navigation</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(31).pdf" style="text-decoration:none;">Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(32).pdf" style="text-decoration:none;">Soft Expert Reward Learning for Vision-and-Language Navigation</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(33).pdf" style="text-decoration:none;">Vision-based Navigation with Language-based Assistance via Imitation Learning with Indirect Intervention</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(34).pdf" style="text-decoration:none;">Transferable Representation Learning in Vision-and-Language Navigation</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(35).pdf" style="text-decoration:none;">Multi-View Learning for Vision-and-Language Navigation</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(36).pdf" style="text-decoration:none;">Are You Looking? Grounding to Multiple Modalities in Vision-and-Language Navigation</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(37).pdf" style="text-decoration:none;">Perceive, Transform, and Act: Multi-Modal Attention Networks for Vision-and-Language Navigation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(38).pdf" style="text-decoration:none;">Help, Anna! Visual Navigation with Natural Multimodal Assistance via Retrospective Curiosity-Encouraging Imitation Learning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(39).pdf" style="text-decoration:none;">Take the Scenic Route:
Improving Generalization in Vision-and-Language Navigation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(40).pdf" style="text-decoration:none;">Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Vision-Language-Navigation-Papers/blob/master/v(41).pdf" style="text-decoration:none;">Sub-Instruction Aware Vision-and-Language Navigation</a></li>
</ul>
